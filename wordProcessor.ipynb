{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Sample static lists for articles, prepositions, and auxiliary verbs\n",
    "auxiliary_verbs = [\"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"will\", \"shall\", \"would\", \"should\", \"can\", \"could\", \"might\", \"must\"]\n",
    "prepositions = [\"in\", \"on\", \"at\", \"by\", \"with\", \"about\", \"under\", \"over\", \"between\", \"among\", \"of\"]\n",
    "articles = [\"the\", \"a\", \"an\"]\n",
    "conjunctions = [\"for\", \"and\", \"nor\", \"but\", \"or\", \"yet\", \"so\", \"after\", \"although\", \"as\", \"because\", \"before\", \"if\", \"since\", \"though\", \"unless\", \"until\", \"when\", \"whenever\", \"where\", \"wherever\", \"while\"]\n",
    "\n",
    "def remove_special_chars(text):\n",
    "  special_chars = \"!@#$%^&*()_+=-[]{}|;:,.<>?/'’‘“”\"\n",
    "  \n",
    "  new_text = ''\n",
    "  for char in text:\n",
    "    if char not in special_chars:\n",
    "      new_text += char\n",
    "  return new_text\n",
    "\n",
    "# Function to determine word type dynamically\n",
    "def findWordType(word, previous_word=None, next_word=None):\n",
    "    # Articles and Prepositions (static list-based detection)\n",
    "    if word in articles:\n",
    "        return \"Article\"\n",
    "\n",
    "    if word in prepositions:\n",
    "        return \"Preposition\"\n",
    "    \n",
    "    # Auxiliary verbs (static list-based detection)\n",
    "    if word in auxiliary_verbs:\n",
    "        return \"Auxiliary Verb\"\n",
    "\n",
    "    # Detecting Conjunction\n",
    "    if word in conjunction:\n",
    "        return \"Conjunction\"\n",
    "\n",
    "    # Verb Detection (simple rule-based)\n",
    "    # If the word is followed by an auxiliary verb, it's likely part of a verb phrase\n",
    "    if previous_word and previous_word.lower() in auxiliary_verbs:\n",
    "        return \"Verb\"\n",
    "    \n",
    "    # Detect base form verbs and conjugations (-ing, -ed, -s)\n",
    "    if word.endswith(\"ing\") or word.endswith(\"ed\") or word.endswith(\"s\"):\n",
    "        return \"Verb\"\n",
    "    \n",
    "    # Check for common nouns\n",
    "    if previous_word in articles or previous_word in prepositions:\n",
    "        return \"Noun\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # If no clear match, return \"Unknown\" or potentially Noun\n",
    "    return \"Noun\"  # Default guess\n",
    "\n",
    "# Function to process a sentence and classify each word's \n",
    "def process_text(text):\n",
    "    words = text.split()  # Split into words\n",
    "    word_types = {}\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        previous_word = words[i - 1] if i > 0 else None\n",
    "        next_word = words[i + 1] if i < len(words) - 1 else None\n",
    "        word = remove_special_chars(word)\n",
    "        word_type = detect_word_type(word, previous_word, next_word)\n",
    "        word_types[word] = word_type\n",
    "\n",
    "    return word_types\n",
    "\n",
    "def frequency_detect(word):\n",
    "    count = 0\n",
    "    word =  word.strip().lower()\n",
    "    for key, _ in word_types.items():\n",
    "        key = key.strip().lower()\n",
    "        if key == word: \n",
    "           count += 1\n",
    "    print(word, count)\n",
    "    return count\n",
    "\n",
    "# Example text input\n",
    "text = \"one of the main issues that degrowth in general is concerned with inequality and its reduction (Hickel, 2021). Hence, distribution and the question of redistribution of wealth, income and resources have continued to resurface in the degrowth literature of (Cosme et al., 2017; Martinez- Alier, 2009; Spangenberg, 2010; Xue et al., 2012). Not so prominently discussed within degrowth, but not less relavent, is the question of money and its role for economic growth itself (see Fig. 1 in Kallis et al., 2018; Strunz et al., 2017). In particular, if money and the monetary system as such indeed fueled the need for economic growth, i. e. if a ‘monetary growth imperative’ existed, as some economists argue (e.g., Binswanger, 2013), there is a pressing need for analyses and proposals on how to design a monetary system that aligns better with the degrowth agenda. Given the immediate relevance of the monetary growth imperative to degrowth, one would expect that degrowth scholarship would prominently address the issue of money. The same applies to the development of concrete policies regarding district issues or monetary system design. However, there is a notable lack in this area. Of concrete policy proposals from the regrowth literature has been lamented repeatedly over the years in different contexts (Berg and Hukkinen, 2011; Bonaiutl, 2018; Demaria et al., 2013; Joutsenvirta, 2016; van den Bergh, 2011), and previous reviews of the degrowth literature have confirmed this on a general level to some extent (Cosme et al, 2017; Fitzpatrick et al., 2022; Sekutova et al., 2013; Vlderia et al., 2014). In particular, a wide variety of different kinds of goals, objectives and in struments proposed in degree with has been attested, as weak as a’commonplace lack of precision in proposals (Fizpatrick el al., 2022, p. 8). One possible explanation for this lack can be found in the relation- ship between degrowth and the state. Given the undertheorized role of the state as a central player in the degrowth transition (Demaria et al., 2019; D’Alisa and Kallis, 2020) degrowth faces “a tension between viewing the state as incapable of initiating transformational change and making a political appeal to it to do precisely this viatargeted eco-social policies” leaving “a lack in research on the strategic implications arising from conceptualizationsof the state and state-civil society relations within degrowth/postgrowth approaches” (Koch, 2020 p. 1). clusters based on similarities in conceptual vocabulary.\"\n",
    "word_types = process_text(text)\n",
    "import pandas as pd\n",
    "row = {}\n",
    "for key, value in word_types.items():\n",
    "        row[key] = {\n",
    "            \"type\": value,\n",
    "            \"freq\": frequency_detect(key),\n",
    "            \"length\": len(key)\n",
    "        }\n",
    "    \n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def get_word_attributes(word_dict):\n",
    "    table_data = []\n",
    "    for word, type in row.items():\n",
    "        table_data.append([word, type['type'], type['freq'], type['length']])\n",
    "    return table_data\n",
    "\n",
    "word_attributes_table = get_word_attributes(word_types)\n",
    "\n",
    "headers = [\"Word\", \"Type\", \"Frequency\", \"Length\"]\n",
    "print(tabulate(word_attributes_table, headers, tablefmt=\"grid\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
